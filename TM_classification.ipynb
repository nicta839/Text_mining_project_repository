{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k7gH7Lx6iKX"
      },
      "source": [
        "# Text classification method performance evaluation using the IMDB movie review dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnyPPKuh66u3"
      },
      "source": [
        "## Package imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6mRgk6UEATD"
      },
      "outputs": [],
      "source": [
        "# using https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671 as base code for most of the notebook\n",
        "\n",
        "# All imports\n",
        "# Data manipulation and NNetworks\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# File manipulation\n",
        "import os\n",
        "import shutil\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "# Time\n",
        "import time\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoXsOvO77Ag_"
      },
      "source": [
        "## Data import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gtkl-Eva4e4Y",
        "outputId": "74c1e7d7-b71f-4ac4-cfa3-20611229a2d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 2s 0us/step\n",
            "84140032/84125825 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Download dataset from repository\n",
        "URL = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(fname=\"aclImdb_v1.tar.gz\", \n",
        "                                  origin=URL,\n",
        "                                  untar=True,\n",
        "                                  cache_dir='.',\n",
        "                                  cache_subdir='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oTP3zEt499m",
        "outputId": "8084e23d-4e0d-42dd-f559-27b3e0ff1e5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['pos', 'labeledBow.feat', 'neg', 'urls_pos.txt', 'unsupBow.feat', 'urls_unsup.txt', 'urls_neg.txt']\n"
          ]
        }
      ],
      "source": [
        "# Create main directory path (\"/aclImdb\")\n",
        "main_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "# Create sub directory path (\"/aclImdb/train\")\n",
        "train_dir = os.path.join(main_dir, 'train')\n",
        "# Remove unsupervised folder\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)\n",
        "# View the final train folder\n",
        "print(os.listdir(train_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuHmXPNE7L0Y"
      },
      "source": [
        "## Data split train/test 80/20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV8u5IEo5RH2",
        "outputId": "2c1f0d3c-e76a-42f6-af23-fc4767665a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# We create a training dataset and a validation \n",
        "# dataset from our \"aclImdb/train\" directory with a 80/20 split for training and testing.\n",
        "train = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=30000, validation_split=0.2, \n",
        "    subset='training', seed=123)\n",
        "\n",
        "test = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=30000, validation_split=0.2, \n",
        "    subset='validation', seed=123)\n",
        "\n",
        "# Use the \"test\" directory for validation\n",
        "valid = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=30000, seed=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7tofH8-5z-S",
        "outputId": "e59fd99b-92f0-4bcf-cfad-957e12a98d86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20000, 2)\n"
          ]
        }
      ],
      "source": [
        "# Training set\n",
        "for i in train.take(1):\n",
        "  train_feat = i[0].numpy()\n",
        "  train_lab = i[1].numpy()\n",
        "\n",
        "train = pd.DataFrame([train_feat, train_lab]).T\n",
        "train.columns = ['Data', 'Label']\n",
        "train['Data'] = train['Data'].str.decode(\"utf-8\")\n",
        "# sanity check\n",
        "#print(train.head())\n",
        "print(train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08aM0pNW6FPH",
        "outputId": "53cc221c-e46b-4e99-8ff5-ea6a62844939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5000, 2)\n"
          ]
        }
      ],
      "source": [
        "# Test set\n",
        "for j in test.take(1):\n",
        "  test_feat = j[0].numpy()\n",
        "  test_lab = j[1].numpy()\n",
        "\n",
        "test = pd.DataFrame([test_feat, test_lab]).T\n",
        "test.columns = ['Data', 'Label']\n",
        "test['Data'] = test['Data'].str.decode(\"utf-8\")\n",
        "# sanity check\n",
        "#print(test.head())\n",
        "print(test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLBRi7-JO6Fq",
        "outputId": "3318f957-6506-4681-dad7-0ecdd8a521e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25000, 2)\n"
          ]
        }
      ],
      "source": [
        "# Validation set\n",
        "for j in valid.take(1):\n",
        "  valid_feat = j[0].numpy()\n",
        "  valid_lab = j[1].numpy()\n",
        "\n",
        "valid = pd.DataFrame([valid_feat, valid_lab]).T\n",
        "valid.columns = ['Data', 'Label']\n",
        "valid['Data'] = valid['Data'].str.decode(\"utf-8\")\n",
        "# sanity check\n",
        "#print(valid.head())\n",
        "print(valid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mURUyRFK7b8w"
      },
      "source": [
        "## Dataset exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrbG36x_6W4a",
        "outputId": "f40e2f64-8653-40f9-de1f-2b46c5d444cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1    25000\n",
            "0    25000\n",
            "Name: Label, dtype: int64\n",
            "0    10057\n",
            "1     9943\n",
            "Name: Label, dtype: int64\n",
            "1    2557\n",
            "0    2443\n",
            "Name: Label, dtype: int64\n",
            "1    12500\n",
            "0    12500\n",
            "Name: Label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_expl = pd.concat([train, test, valid], ignore_index = True)\n",
        "\n",
        "print(df_expl['Label'].value_counts())\n",
        "print(train['Label'].value_counts())\n",
        "print(test['Label'].value_counts())\n",
        "print(valid['Label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbaRK9wvPY0S"
      },
      "source": [
        "The dataset is balanced for the two classes and for each split of the data. There is no strong imbalance that justifies a different sampling of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWCVi0tHP_DN",
        "outputId": "2201e640-cbad-4611-a23b-3b3536508c72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max string length of review:  13704\n",
            "Max word length of review:  2470\n",
            "Min string length of review:  52\n",
            "Min word length of review:  10\n",
            "Mean string length of review:  1325\n",
            "Mean word length of review:  234\n"
          ]
        }
      ],
      "source": [
        "# Dataset statistics\n",
        "# max length of review (word and character)\n",
        "print('Max string length of review: ', round(np.max(df_expl['Data'].apply(lambda x: len(x)))))\n",
        "print('Max word length of review: ', round(np.max(df_expl['Data'].apply(lambda x: len(x.split())))))\n",
        "# min length of review (word and character)\n",
        "print('Min string length of review: ', round(np.min(df_expl['Data'].apply(lambda x: len(x)))))\n",
        "print('Min word length of review: ', round(np.min(df_expl['Data'].apply(lambda x: len(x.split())))))\n",
        "# avg length of review (word and character)\n",
        "print('Mean string length of review: ', round(np.mean(df_expl['Data'].apply(lambda x: len(x)))))\n",
        "print('Mean word length of review: ', round(np.mean(df_expl['Data'].apply(lambda x: len(x.split())))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anGbjWmgSlnL"
      },
      "source": [
        "There is a large spread between the minimum and the maximum number of words or string length in this dataset. We will visualize the distribution in terms of word length of reviews to better the dataset. Visualizing word length makes more sense as stop words (usually short) are still included at this moment. We shall also visualize the distribution of reviews by word length depending on the class (positive or negative review)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Y8yTEIDZSlI7",
        "outputId": "0ce679f3-b4db-48f7-dbd3-0e983ecc16f1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot distribution of reviews by word length\n",
        "plt.hist([len(t.split()) for t in df_expl['Data']], 100)\n",
        "plt.xlabel('Word length of reviews')\n",
        "plt.ylabel('Number of reviews')\n",
        "plt.rcParams[\"figure.figsize\"] = (18.5,10.5)\n",
        "plt.xlim(0,2500)\n",
        "plt.ylim(0, 8000)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5whQ5Y6Yf0F"
      },
      "source": [
        "The distribution is heavily skewed towards 200-300 word length as expected, with long reviews being rare. This is somewhat expected as these movie reviews can be submitted to IMDB by any user. We will now see if this distribution is also present for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuUZl74xZGJ1"
      },
      "outputs": [],
      "source": [
        "# negative reviews\n",
        "neg_rev = df_expl[df_expl['Label'] == 0]['Data']\n",
        "# positive reviews\n",
        "pos_rev = df_expl[df_expl['Label'] == 1]['Data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "pRpXg5ZVZhGx",
        "outputId": "d65ef6b9-1a13-453f-a0af-b5bc5b1a2f6f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1332x756 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot negative review distribution by word length\n",
        "\n",
        "plt.hist([len(t.split()) for t in neg_rev], 100)\n",
        "plt.xlabel('Word length of reviews')\n",
        "plt.ylabel('Number of reviews')\n",
        "plt.rcParams[\"figure.figsize\"] = (18.5,10.5)\n",
        "plt.xlim(0,2500)\n",
        "plt.ylim(0, 4000)\n",
        "plt.title('Negative review distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "GDDh94LNZ8X_",
        "outputId": "c2e2110e-9831-487e-a9b0-f9c30a1cbda8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1332x756 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot negative review distribution by word length\n",
        "\n",
        "plt.hist([len(t.split()) for t in pos_rev], 100)\n",
        "plt.xlabel('Word length of reviews')\n",
        "plt.ylabel('Number of reviews')\n",
        "plt.rcParams[\"figure.figsize\"] = (18.5,10.5)\n",
        "plt.xlim(0,2500)\n",
        "plt.ylim(0, 4000)\n",
        "plt.title('positive review distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHK1B9xKaSrY"
      },
      "source": [
        "These distributions are interesting to compare to one another. We can see that the number of words used for a negative distribution seems to be more numerous for very short text (< 100 words) and also for text longer than for the review average length. The distribution of negative reviews is heavier around the average than for the positive reviews. The latter's distribution decays faster. We shall check the similar word/string average statistics used previously for positive and negative reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVaahGIyhZks",
        "outputId": "1c302bb4-3fb6-4304-d0c6-08933453436a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#######################################################\n",
            "Negative reviews statistics\n",
            "Max string length of review:  8969\n",
            "Max word length of review:  1522\n",
            "Min string length of review:  52\n",
            "Min word length of review:  10\n",
            "Mean string length of review:  1303\n",
            "Mean word length of review:  231\n",
            "########################################################\n",
            "positive reviews statistics\n",
            "Max string length of review:  13704\n",
            "Max word length of review:  2470\n",
            "Min string length of review:  70\n",
            "Min word length of review:  12\n",
            "Mean string length of review:  1347\n",
            "Mean word length of review:  237\n"
          ]
        }
      ],
      "source": [
        "# Dataset statistics\n",
        "# Negative reviews\n",
        "# max length of review (word and character)\n",
        "print('#######################################################')\n",
        "print('Negative reviews statistics')\n",
        "print('Max string length of review: ', round(np.max(neg_rev.apply(lambda x: len(x)))))\n",
        "print('Max word length of review: ', round(np.max(neg_rev.apply(lambda x: len(x.split())))))\n",
        "# min length of review (word and character)\n",
        "print('Min string length of review: ', round(np.min(neg_rev.apply(lambda x: len(x)))))\n",
        "print('Min word length of review: ', round(np.min(neg_rev.apply(lambda x: len(x.split())))))\n",
        "# avg length of review (word and character)\n",
        "print('Mean string length of review: ', round(np.mean(neg_rev.apply(lambda x: len(x)))))\n",
        "print('Mean word length of review: ', round(np.mean(neg_rev.apply(lambda x: len(x.split())))))\n",
        "\n",
        "print('########################################################')\n",
        "print('positive reviews statistics')\n",
        "print('Max string length of review: ', round(np.max(pos_rev.apply(lambda x: len(x)))))\n",
        "print('Max word length of review: ', round(np.max(pos_rev.apply(lambda x: len(x.split())))))\n",
        "# min length of review (word and character)\n",
        "print('Min string length of review: ', round(np.min(pos_rev.apply(lambda x: len(x)))))\n",
        "print('Min word length of review: ', round(np.min(pos_rev.apply(lambda x: len(x.split())))))\n",
        "# avg length of review (word and character)\n",
        "print('Mean string length of review: ', round(np.mean(pos_rev.apply(lambda x: len(x)))))\n",
        "print('Mean word length of review: ', round(np.mean(pos_rev.apply(lambda x: len(x.split())))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMUpAAqCif7h"
      },
      "source": [
        "Except for the maximum length, that might be an outlier, the average length of both positive and negative reviews are similar to each other. This underlines the importance of the distribution visualization as it gives more insight into the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At544JTPjauZ"
      },
      "source": [
        "## Text normalization\n",
        "\n",
        "We now wish to remove text contractions, stop words, special characters, parse HTML text and lemmatize the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5MJ6ZMUoOXM",
        "outputId": "3c1ee14d-8163-4fa9-d775-4a35af0f745f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    Canadian director Vincenzo Natali took the art...\n",
              "1    I gave this film 10 not because it is a superb...\n",
              "2    I admit to being somewhat jaded about the movi...\n",
              "3    For a long time, 'The Menagerie' was my favori...\n",
              "Name: Data, dtype: object"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example\n",
        "example = df_expl['Data'][0]\n",
        "# print(example)\n",
        "\n",
        "examples = df_expl['Data'][0:4]\n",
        "examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQNT1ViSlEqq",
        "outputId": "eb9e5a5b-32ba-427e-f946-f89eedd5d122"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Imports for text normalization\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.stem.porter import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcm8Tvr7qALH"
      },
      "outputs": [],
      "source": [
        "# Text tokenizer\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "nlp = nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMJt5JIwnt9B"
      },
      "outputs": [],
      "source": [
        "# The following text normalization functions are inspired from: https://www.kaggle.com/code/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews\n",
        "\n",
        "\n",
        "# Define necessary functions\n",
        "\n",
        "# remove html\n",
        "def strip_html(text):\n",
        "  soup = BeautifulSoup(text, \"html.parser\")\n",
        "  return soup.get_text()\n",
        "\n",
        "# remove brackets\n",
        "def remove_brackets(text):\n",
        "  return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "# remove special characters\n",
        "def remove_special_chara(text):\n",
        "  pattern = r'[^a-zA-z0-9\\s]'\n",
        "  text = re.sub(pattern,'',text)\n",
        "  return text\n",
        "\n",
        "# lower case\n",
        "def lower_case(text):\n",
        "  text = text.lower()\n",
        "  return text \n",
        "\n",
        "# remove new lines \\n\n",
        "def remove_new_line(text):\n",
        "  text = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',text)\n",
        "  return text\n",
        "\n",
        "# stem word endings\n",
        "def stemmer(text):\n",
        "  ps = nltk.porter.PorterStemmer()\n",
        "  text = ' '.join([ps.stem(word) for word in text.split()])\n",
        "  return(text)\n",
        "\n",
        "# lemmatization\n",
        "def lemmatize_text(text):\n",
        "  text = nlp(text)\n",
        "  text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
        "  return text\n",
        "\n",
        "# remove stop words\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNEe6xhU8tPt"
      },
      "outputs": [],
      "source": [
        "# function to normalize text\n",
        "\n",
        "def text_normer(text):\n",
        "  text = text.apply(strip_html)\n",
        "  text = text.apply(remove_brackets)\n",
        "  text = text.apply(remove_special_chara)\n",
        "  text = text.apply(lower_case)\n",
        "  text = text.apply(remove_new_line)\n",
        "  # Unexpected results\n",
        "  # text = text.apply(stemmer)\n",
        "  text = text.apply(lemmatize_text)\n",
        "  text = text.apply(remove_stopwords)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK-TIN2n9rvI",
        "outputId": "1912527d-78c5-41d0-82ea-d57d897991d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "canadian director vincenzo natali take arthouse circuit storm intriguing astonishingly intelligent cube personal favourite sf film 90 frame basic conceit group stranger trap maze shape like giant cube shoot entirely one set take idea fascinating direction eagerly await natalis followup although take five year mount another project delighted say worth wait cypher fascinating exploration one man place world completely logical chain event find situation beyond controli want reveal much plot one joy cypher different avenue take refreshing day age see sf film one idea head cypher filmmorgan sullivan jeremy northam one blandest people ever walk planet hire company digicorp send different part america record different seminar bewilderment unbelievably bore cover topic mundane shaving cream cheesewhile morgan wait one seminar run rita foster impeccably cast lucy liu definition ice maiden give brushoff something find irresistible surprising consider dry marriage rita turn another one morgans seminar tell life appear say anything plot would cheapen impact rest film well tortuous path much fun followas cube natali show quite talent encompass seemingly ordinary people take familiar basically see happen thrust unknown cypher follow similar pattern carbon copy cube inspirationcypher film common conspiracy thriller paranoia story one great thing cypher way theme creep story without knowledge morgan realise false identity piece much large puzzle much shock himone thing distinguish cypher cube much polished cube confine minimalist setting shoestring budget cast unknown cypher also low budget natali economise much allow broaden horizon launch morgan amazing journey labyrinth identitynatalis direction exceptional deft hand rein amazing camera angle enormity digicorp building vast robust office block conjunction insignificant speck morgan stand outside colour appear bleed picture compliment tone film perfectly modern day filmnoirthe acting uniformly excellent throughout jeremy northam sympathetic figure loveless marriage question identity performance excellent modulated literally seem transform right eye clinical spineless wimp confident man anything preserve new identitydavid hewlett put welcome appearance make impact cube reside secret silo look like borrow man black scene one good exercise carefully calculate suspense paranoia supposed expert identify doubleagent fantastic piece write brilliantly act hewlett look morgan draw complex mind gamebut lucy liu scene stealer often cast film potential utilise full effect cypher finally give character fit like glove rita aloof guard femme fatale liu inhabit relish perk every time appear always control reduce room silence power icy stare alonething come gratifying end conclude ambiguous note way cube morgan deserve happy ending put ringer like cheer final scene perfect final moment come ray sunshine gloomy 90 minutescypher succeed count engage shocking always entertain everything total recall want come refreshing antidote overwhelming inexplicable matrixa fine followup natali committed fan man superb stuff\n"
          ]
        }
      ],
      "source": [
        "# Test on example\n",
        "normalization_test = text_normer(examples)\n",
        "print(normalization_test[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNlrBJViAhjk"
      },
      "source": [
        "We can now normalize our data and save it for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QQrbfbuAg3b"
      },
      "outputs": [],
      "source": [
        "# tic = time.time()\n",
        "# normalized_train = text_normer(train['Data'])\n",
        "# print(f\"Time to normalize training data (20k rows): {time.time() - tic:.2f} s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfzEqvFfF1OG"
      },
      "outputs": [],
      "source": [
        "# normalized_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "157iy0XLHDMC"
      },
      "outputs": [],
      "source": [
        "# normalize test data\n",
        "# tic = time.time()\n",
        "# normalized_test = text_normer(test['Data'])\n",
        "# print(f\"Time to normalize test data (5k rows): {time.time() - tic:.2f} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsWmws-pHOgB"
      },
      "outputs": [],
      "source": [
        "# normalize validation data\n",
        "# tic = time.time()\n",
        "# normalized_valid = text_normer(valid['Data'])\n",
        "# print(f\"Time to normalize validation data (25k rows): {time.time() - tic:.2f} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nuq6MCpcPRjI"
      },
      "outputs": [],
      "source": [
        "# # Collect data in appropriate dataframes and save\n",
        "# # training data\n",
        "# df_norm_train = pd.DataFrame().assign(Data = normalized_train, Label = train['Label'])\n",
        "# # test data\n",
        "# df_norm_test = pd.DataFrame().assign(Data = normalized_test, Label = test['Label'])\n",
        "# # validation data\n",
        "# df_norm_valid = pd.DataFrame().assign(Data = normalized_valid, Label = valid['Label'])\n",
        "\n",
        "# # save everything as CSV\n",
        "# df_norm_train.to_csv('normalized_train.csv', index = False)\n",
        "# df_norm_test.to_csv('normalized_test.csv', index = False)\n",
        "# df_norm_valid.to_csv('normalized_valid.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEGRTjFBrVae"
      },
      "outputs": [],
      "source": [
        "# load back data\n",
        "df_train = pd.read_csv('normalized_train.csv')\n",
        "df_test = pd.read_csv('normalized_test.csv')\n",
        "df_valid = pd.read_csv('normalized_valid.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPJQjp3_Rzui"
      },
      "source": [
        "## Baseline comparison\n",
        "\n",
        "We compare how the different baseline methods (Logistic Regression, Ranfom Forest Classifier and Support Vector Machines) perform accuracy-wise and time wise using two different sparse vectorization for feature extraction (CountVectorizer and Tfidfvectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzoVZN-AZuxI"
      },
      "outputs": [],
      "source": [
        "# Vectorizer imports\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from gensim.models import Word2Vec\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRxZFK0TRzWK"
      },
      "outputs": [],
      "source": [
        "# The following code is inspired from the code implementation for the last question of Lab2 (text classification lab) and \n",
        "# https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html\n",
        "\n",
        "# LogisticRegression Pipeline\n",
        "pipe_lr = Pipeline([\n",
        "    (\"countVectorizer\", CountVectorizer()),\n",
        "    (\"LogisticRegression\", LogisticRegression(multi_class=\"multinomial\", max_iter=100))])\n",
        "\n",
        "# RandomForestClassifier Pipeline\n",
        "pipe_rf = Pipeline([\n",
        "    ('countVectorizer', CountVectorizer()),\n",
        "    ('RandomForestClassifier', RandomForestClassifier(random_state=0))])\n",
        "\n",
        "# SVC\n",
        "pipe_svm = Pipeline([\n",
        "    ('countVectorizer', CountVectorizer()),\n",
        "    ('SVM', SVC(random_state=0))])\n",
        "\n",
        "\n",
        "# Define pipeline parameters for all models\n",
        "params_lr = {\n",
        "    \"countVectorizer__ngram_range\": [(1,1), (1,2)],\n",
        "    \"countVectorizer__binary\": [True, False],\n",
        "    \"LogisticRegression__C\": [0.5, 1.0],\n",
        "    #\"LogisticRegression__solver\": [\"newton-cg\", \"lbfgs\"],\n",
        "    #\"LogisticRegression__warm_start\": [True, False]\n",
        "}\n",
        "\n",
        "params_rf = {\n",
        "    \"countVectorizer__ngram_range\": [(1,1), (1,2)],\n",
        "    \"countVectorizer__binary\": [True, False],\n",
        "    \"RandomForestClassifier__criterion\": [\"gini\", \"entropy\"],\n",
        "    #\"RandomForestClassifier__bootstrap\": [True, False],\n",
        "    #\"RandomForestClassifier__warm_start\": [True, False]\n",
        "}\n",
        "\n",
        "params_svm = {\n",
        "    \"countVectorizer__ngram_range\": [(1,1), (1,2)],\n",
        "    \"countVectorizer__binary\": [True, False],\n",
        "    \"SVM__kernel\": [\"linear\", \"rbf\", \"sigmoid\"], \n",
        "    #\"SVM__C\": [0.5, 1.0]\n",
        "}\n",
        "\n",
        "grid_param_lr = GridSearchCV(\n",
        "    estimator=pipe_lr,\n",
        "    param_grid=params_lr,\n",
        "    scoring='accuracy',\n",
        "    cv=3) \n",
        "\n",
        "grid_param_rf = GridSearchCV(\n",
        "    estimator=pipe_rf,\n",
        "    param_grid=params_rf,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=3)\n",
        "\n",
        "grid_param_svm = GridSearchCV(\n",
        "    estimator=pipe_svm,\n",
        "    param_grid=params_svm,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=3)\n",
        "\n",
        "pipelines = [(grid_param_lr, params_lr, pipe_lr), (grid_param_rf, params_rf, pipe_rf), (grid_param_svm, params_svm, pipe_svm)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_SBNhAH0ovZ",
        "outputId": "ab4f9ab3-0265-44c7-e155-248103995ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "Pipeline: ['countVectorizer', 'LogisticRegression']\n",
            "Parameters:\n",
            "{'LogisticRegression__C': [0.5, 1.0],\n",
            " 'countVectorizer__binary': [True, False],\n",
            " 'countVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
            "Done in 756.006s\n",
            "\n",
            "Best score: 0.880\n",
            "Best parameters set:\n",
            "\tLogisticRegression__C: 1.0\n",
            "\tcountVectorizer__binary: False\n",
            "\tcountVectorizer__ngram_range: (1, 2)\n",
            "\n",
            "Classification report for optimal parameters (training set)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     10057\n",
            "           1       1.00      1.00      1.00      9943\n",
            "\n",
            "    accuracy                           1.00     20000\n",
            "   macro avg       1.00      1.00      1.00     20000\n",
            "weighted avg       1.00      1.00      1.00     20000\n",
            "\n",
            "\n",
            "Classification report for optimal parameters (test data)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88      2443\n",
            "           1       0.89      0.89      0.89      2557\n",
            "\n",
            "    accuracy                           0.89      5000\n",
            "   macro avg       0.89      0.89      0.89      5000\n",
            "weighted avg       0.89      0.89      0.89      5000\n",
            "\n",
            "################################################################\n",
            "Performing grid search...\n",
            "Pipeline: ['countVectorizer', 'RandomForestClassifier']\n",
            "Parameters:\n",
            "{'RandomForestClassifier__criterion': ['gini', 'entropy'],\n",
            " 'countVectorizer__binary': [True, False],\n",
            " 'countVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
            "Done in 2044.244s\n",
            "\n",
            "Best score: 0.849\n",
            "Best parameters set:\n",
            "\tRandomForestClassifier__criterion: 'entropy'\n",
            "\tcountVectorizer__binary: False\n",
            "\tcountVectorizer__ngram_range: (1, 2)\n",
            "\n",
            "Classification report for optimal parameters (training set)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     10057\n",
            "           1       1.00      1.00      1.00      9943\n",
            "\n",
            "    accuracy                           1.00     20000\n",
            "   macro avg       1.00      1.00      1.00     20000\n",
            "weighted avg       1.00      1.00      1.00     20000\n",
            "\n",
            "\n",
            "Classification report for optimal parameters (test data)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.84      0.85      2443\n",
            "           1       0.85      0.87      0.86      2557\n",
            "\n",
            "    accuracy                           0.86      5000\n",
            "   macro avg       0.86      0.86      0.86      5000\n",
            "weighted avg       0.86      0.86      0.86      5000\n",
            "\n",
            "################################################################\n",
            "Performing grid search...\n",
            "Pipeline: ['countVectorizer', 'SVM']\n",
            "Parameters:\n",
            "{'SVM__kernel': ['linear', 'rbf', 'sigmoid'],\n",
            " 'countVectorizer__binary': [True, False],\n",
            " 'countVectorizer__ngram_range': [(1, 1), (1, 2)]}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "from time import time\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "##### runtime ended prematurely (restarting at failure)\n",
        "# pipelines = [(grid_param_svm, params_svm, pipe_svm)]\n",
        "#####\n",
        "for pipe in pipelines:\n",
        "    print(\"Performing grid search...\")\n",
        "    print(\"Pipeline:\", [name for name, _ in pipe[2].steps])\n",
        "    print(\"Parameters:\")\n",
        "    pprint(pipe[1])\n",
        "    t0 = time()\n",
        "    pipe[0].fit(df_train[\"Data\"], df_train[\"Label\"])\n",
        "    print(\"Done in %0.3fs\\n\" % (time() - t0))\n",
        "    print(\"Best score: %0.3f\" % pipe[0].best_score_)\n",
        "    print(\"Best parameters set:\")\n",
        "    best_parameters = pipe[0].best_estimator_.get_params()\n",
        "    for param_name in sorted(pipe[1].keys()):\n",
        "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
        "        \n",
        "    # On training data\n",
        "    predict_train = pipe[0].best_estimator_.predict(df_train[\"Data\"])\n",
        "    # On test data\n",
        "    predict_test = pipe[0].best_estimator_.predict(df_test[\"Data\"])\n",
        "\n",
        "    # classification report for optimal parameters (training set)\n",
        "    print(\"\\nClassification report for optimal parameters (training set)\\n\")\n",
        "    print(classification_report(df_train[\"Label\"], predict_train))\n",
        "\n",
        "    # classification report for optimal parameters (test set)\n",
        "    print(\"\\nClassification report for optimal parameters (test data)\\n\")\n",
        "    print(classification_report(df_test[\"Label\"], predict_test))\n",
        "    \n",
        "    print(\"################################################################\")\n",
        "\n",
        "    ## The result shown below is the attempt at 3-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBMApt5end8d"
      },
      "outputs": [],
      "source": [
        "### output for 5-fold CV\n",
        "\n",
        "# Performing grid search...\n",
        "# Pipeline: ['countVectorizer', 'LogisticRegression']\n",
        "# Parameters:\n",
        "# {'LogisticRegression__C': [0.5, 1.0],\n",
        "#  'countVectorizer__binary': [True, False],\n",
        "#  'countVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
        "# Done in 1827.272s\n",
        "\n",
        "# Best score: 0.883\n",
        "# Best parameters set:\n",
        "# \tLogisticRegression__C: 1.0\n",
        "# \tcountVectorizer__binary: False\n",
        "# \tcountVectorizer__ngram_range: (1, 2)\n",
        "\n",
        "# Classification report for optimal parameters (training set)\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       1.00      1.00      1.00     10057\n",
        "#            1       1.00      1.00      1.00      9943\n",
        "\n",
        "#     accuracy                           1.00     20000\n",
        "#    macro avg       1.00      1.00      1.00     20000\n",
        "# weighted avg       1.00      1.00      1.00     20000\n",
        "\n",
        "\n",
        "# Classification report for optimal parameters (test data)\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.88      0.88      0.88      2443\n",
        "#            1       0.89      0.89      0.89      2557\n",
        "\n",
        "#     accuracy                           0.89      5000\n",
        "#    macro avg       0.89      0.89      0.89      5000\n",
        "# weighted avg       0.89      0.89      0.89      5000\n",
        "\n",
        "# ################################################################\n",
        "# Performing grid search...\n",
        "# Pipeline: ['countVectorizer', 'RandomForestClassifier']\n",
        "# Parameters:\n",
        "# {'RandomForestClassifier__criterion': ['gini', 'entropy'],\n",
        "#  'countVectorizer__binary': [True, False],\n",
        "#  'countVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
        "# Done in 6422.180s\n",
        "\n",
        "# Best score: 0.854\n",
        "# Best parameters set:\n",
        "# \tRandomForestClassifier__criterion: 'entropy'\n",
        "# \tcountVectorizer__binary: False\n",
        "# \tcountVectorizer__ngram_range: (1, 2)\n",
        "\n",
        "# Classification report for optimal parameters (training set)\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       1.00      1.00      1.00     10057\n",
        "#            1       1.00      1.00      1.00      9943\n",
        "\n",
        "#     accuracy                           1.00     20000\n",
        "#    macro avg       1.00      1.00      1.00     20000\n",
        "# weighted avg       1.00      1.00      1.00     20000\n",
        "\n",
        "\n",
        "# Classification report for optimal parameters (test data)\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.86      0.84      0.85      2443\n",
        "#            1       0.85      0.87      0.86      2557\n",
        "\n",
        "#     accuracy                           0.86      5000\n",
        "#    macro avg       0.86      0.86      0.86      5000\n",
        "# weighted avg       0.86      0.86      0.86      5000\n",
        "\n",
        "# ################################################################\n",
        "# Performing grid search...\n",
        "# Pipeline: ['countVectorizer', 'SVM']\n",
        "# Parameters:\n",
        "# {'SVM__kernel': ['linear', 'rbf', 'sigmoid'],\n",
        "#  'countVectorizer__binary': [True, False],\n",
        "#  'countVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
        "\n",
        "# Performing grid search...\n",
        "# Pipeline: ['countVectorizer', 'SVM']\n",
        "# Parameters:\n",
        "# {'SVM__kernel': ['linear', 'rbf', 'sigmoid'],\n",
        "#  'countVectorizer__binary': [True, False],\n",
        "#  'countVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
        "# Done in 31621.770s\n",
        "\n",
        "# Best score: 0.880\n",
        "# Best parameters set:\n",
        "# \tSVM__kernel: 'linear'\n",
        "# \tcountVectorizer__binary: False\n",
        "# \tcountVectorizer__ngram_range: (1, 2)\n",
        "\n",
        "# Classification report for optimal parameters (training set)\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       1.00      1.00      1.00     10057\n",
        "#            1       1.00      1.00      1.00      9943\n",
        "\n",
        "#     accuracy                           1.00     20000\n",
        "#    macro avg       1.00      1.00      1.00     20000\n",
        "# weighted avg       1.00      1.00      1.00     20000\n",
        "\n",
        "\n",
        "# Classification report for optimal parameters (test data)\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.88      0.88      0.88      2443\n",
        "#            1       0.89      0.88      0.88      2557\n",
        "\n",
        "#     accuracy                           0.88      5000\n",
        "#    macro avg       0.88      0.88      0.88      5000\n",
        "# weighted avg       0.88      0.88      0.88      5000\n",
        "\n",
        "# ################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW6s3qT12oJd"
      },
      "outputs": [],
      "source": [
        "# Tfidf vectorizer\n",
        "\n",
        "# LogisticRegression Pipeline\n",
        "pipe_lr = Pipeline([\n",
        "    (\"tfidfVectorizer\", TfidfVectorizer()),\n",
        "    (\"LogisticRegression\", LogisticRegression(multi_class=\"multinomial\", max_iter=100))])\n",
        "\n",
        "# RandomForestClassifier Pipeline\n",
        "pipe_rf = Pipeline([\n",
        "    ('tfidfVectorizer', TfidfVectorizer()),\n",
        "    ('RandomForestClassifier', RandomForestClassifier(random_state=0))])\n",
        "\n",
        "# SVC\n",
        "pipe_svm = Pipeline([\n",
        "    ('tfidfVectorizer', TfidfVectorizer()),\n",
        "    ('SVM', SVC(random_state=0))])\n",
        "\n",
        "\n",
        "# Define pipeline parameters for all models\n",
        "params_lr = {\n",
        "    \"tfidfVectorizer__ngram_range\": [(1,1), (1,2)],\n",
        "    \"tfidfVectorizer__binary\": [True, False],\n",
        "    \"LogisticRegression__C\": [0.5, 1.0],\n",
        "    #\"LogisticRegression__solver\": [\"newton-cg\", \"lbfgs\"],\n",
        "    #\"LogisticRegression__warm_start\": [True, False]\n",
        "}\n",
        "\n",
        "params_rf = {\n",
        "    \"tfidfVectorizer__ngram_range\": [(1,1), (1,2)],\n",
        "    \"tfidfVectorizer__binary\": [True, False],\n",
        "    \"RandomForestClassifier__criterion\": [\"gini\", \"entropy\"],\n",
        "    #\"RandomForestClassifier__bootstrap\": [True, False],\n",
        "    #\"RandomForestClassifier__warm_start\": [True, False]\n",
        "}\n",
        "\n",
        "params_svm = {\n",
        "    \"tfidfVectorizer__ngram_range\": [(1,1), (1,2)],\n",
        "    # \"tfidfVectorizer__ngram_range\": [(1,2)],\n",
        "    \"tfidfVectorizer__binary\": [True, False],\n",
        "    # \"tfidfVectorizer__binary\": [False],\n",
        "    \"SVM__kernel\": [\"linear\", \"rbf\", \"sigmoid\"],\n",
        "    # \"SVM__kernel\": [\"linear\"], \n",
        "    #\"SVM__C\": [0.5, 1.0]\n",
        "}\n",
        "\n",
        "grid_param_lr = GridSearchCV(\n",
        "    estimator=pipe_lr,\n",
        "    param_grid=params_lr,\n",
        "    scoring='accuracy',\n",
        "    cv=3) \n",
        "\n",
        "grid_param_rf = GridSearchCV(\n",
        "    estimator=pipe_rf,\n",
        "    param_grid=params_rf,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=3)\n",
        "\n",
        "grid_param_svm = GridSearchCV(\n",
        "    estimator=pipe_svm,\n",
        "    param_grid=params_svm,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=3)\n",
        "\n",
        "pipelines = [(grid_param_lr, params_lr, pipe_lr), (grid_param_rf, params_rf, pipe_rf), (grid_param_svm, params_svm, pipe_svm)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L546mi9rrrxT"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "from time import time\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "##### runtime ended prematurely (restarting at failure)\n",
        "# pipelines = [(grid_param_svm, params_svm, pipe_svm)]\n",
        "#####\n",
        "for pipe in pipelines:\n",
        "    print(\"Performing grid search...\")\n",
        "    print(\"Pipeline:\", [name for name, _ in pipe[2].steps])\n",
        "    print(\"Parameters:\")\n",
        "    pprint(pipe[1])\n",
        "    t0 = time()\n",
        "    pipe[0].fit(df_train[\"Data\"], df_train[\"Label\"])\n",
        "    print(\"Done in %0.3fs\\n\" % (time() - t0))\n",
        "    print(\"Best score: %0.3f\" % pipe[0].best_score_)\n",
        "    print(\"Best parameters set:\")\n",
        "    best_parameters = pipe[0].best_estimator_.get_params()\n",
        "    for param_name in sorted(pipe[1].keys()):\n",
        "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
        "        \n",
        "    # On training data\n",
        "    predict_train = pipe[0].best_estimator_.predict(df_train[\"Data\"])\n",
        "    # On test data\n",
        "    predict_test = pipe[0].best_estimator_.predict(df_test[\"Data\"])\n",
        "\n",
        "    # classification report for optimal parameters (training set)\n",
        "    print(\"\\nClassification report for optimal parameters (training set)\\n\")\n",
        "    print(classification_report(df_train[\"Label\"], predict_train))\n",
        "\n",
        "    # classification report for optimal parameters (test set)\n",
        "    print(\"\\nClassification report for optimal parameters (test data)\\n\")\n",
        "    print(classification_report(df_test[\"Label\"], predict_test))\n",
        "    \n",
        "    print(\"################################################################\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOfdpYZXW3qz"
      },
      "outputs": [],
      "source": [
        "## Result of 5 fold CV \n",
        "\n",
        "# Performing grid search...\n",
        "# Pipeline: ['tfidfVectorizer', 'LogisticRegression']\n",
        "# Parameters:\n",
        "# {'LogisticRegression__C': [0.5, 1.0],\n",
        "#  'tfidfVectorizer__binary': [True, False],\n",
        "#  'tfidfVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
        "# Done in 1164.510s\n",
        "\n",
        "# Best score: 0.883\n",
        "# Best parameters set:\n",
        "# \tLogisticRegression__C: 1.0\n",
        "# \ttfidfVectorizer__binary: True\n",
        "# \ttfidfVectorizer__ngram_range: (1, 2)\n",
        "\n",
        "# Classification report for optimal parameters (training set)\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.99      0.99      0.99     10057\n",
        "#            1       0.99      0.99      0.99      9943\n",
        "\n",
        "#     accuracy                           0.99     20000\n",
        "#    macro avg       0.99      0.99      0.99     20000\n",
        "# weighted avg       0.99      0.99      0.99     20000\n",
        "\n",
        "\n",
        "# Classification report for optimal parameters (test data)\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.88      0.88      0.88      2443\n",
        "#            1       0.89      0.89      0.89      2557\n",
        "\n",
        "#     accuracy                           0.89      5000\n",
        "#    macro avg       0.89      0.89      0.89      5000\n",
        "# weighted avg       0.89      0.89      0.89      5000\n",
        "\n",
        "# ################################################################\n",
        "# Performing grid search...\n",
        "# Pipeline: ['tfidfVectorizer', 'RandomForestClassifier']\n",
        "# Parameters:\n",
        "# {'RandomForestClassifier__criterion': ['gini', 'entropy'],\n",
        "#  'tfidfVectorizer__binary': [True, False],\n",
        "#  'tfidfVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
        "# Done in 6561.010s\n",
        "\n",
        "# Best score: 0.848\n",
        "# Best parameters set:\n",
        "# \tRandomForestClassifier__criterion: 'entropy'\n",
        "# \ttfidfVectorizer__binary: False\n",
        "# \ttfidfVectorizer__ngram_range: (1, 2)\n",
        "\n",
        "# Classification report for optimal parameters (training set)\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       1.00      1.00      1.00     10057\n",
        "#            1       1.00      1.00      1.00      9943\n",
        "\n",
        "#     accuracy                           1.00     20000\n",
        "#    macro avg       1.00      1.00      1.00     20000\n",
        "# weighted avg       1.00      1.00      1.00     20000\n",
        "\n",
        "\n",
        "# Classification report for optimal parameters (test data)\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.83      0.88      0.86      2443\n",
        "#            1       0.88      0.83      0.86      2557\n",
        "\n",
        "#     accuracy                           0.86      5000\n",
        "#    macro avg       0.86      0.86      0.86      5000\n",
        "# weighted avg       0.86      0.86      0.86      5000\n",
        "\n",
        "# ################################################################\n",
        "\n",
        "# Performing grid search...\n",
        "# Pipeline: ['tfidfVectorizer', 'SVM']\n",
        "# Parameters:\n",
        "# {'SVM__kernel': ['linear'],\n",
        "#  'tfidfVectorizer__binary': [False],\n",
        "#  'tfidfVectorizer__ngram_range': [(1, 2)]}\n",
        "# Done in 5830.067s\n",
        "\n",
        "# Best score: 0.892\n",
        "# Best parameters set:\n",
        "# \tSVM__kernel: 'linear'\n",
        "# \ttfidfVectorizer__binary: False\n",
        "# \ttfidfVectorizer__ngram_range: (1, 2)\n",
        "\n",
        "# Classification report for optimal parameters (training set)\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       1.00      1.00      1.00     10057\n",
        "#            1       1.00      1.00      1.00      9943\n",
        "\n",
        "#     accuracy                           1.00     20000\n",
        "#    macro avg       1.00      1.00      1.00     20000\n",
        "# weighted avg       1.00      1.00      1.00     20000\n",
        "\n",
        "\n",
        "# Classification report for optimal parameters (test data)\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.90      0.89      0.89      2443\n",
        "#            1       0.89      0.91      0.90      2557\n",
        "\n",
        "#     accuracy                           0.90      5000\n",
        "#    macro avg       0.90      0.90      0.90      5000\n",
        "# weighted avg       0.90      0.90      0.90      5000\n",
        "\n",
        "# ################################################################"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TM_classification.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}